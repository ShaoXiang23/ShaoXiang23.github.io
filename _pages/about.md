---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<div class="card hero-card">
  <div style="font-size:16px;font-weight:700;opacity:.9;">
    Postdoctoral Researcher ¬∑ Zhejiang University ¬∑ Computer Vision / Geometry-aware Learning
  </div>

  <div style="margin-top:10px; font-size:18px;">
    <a class="pill" href="#about"><i class="fas fa-user"></i> About</a>
    <a class="pill" href="#contact"><i class="fas fa-envelope"></i> Contact</a>
    <a class="pill" href="#experience"><i class="fas fa-briefcase"></i> Experience</a>
    <a class="pill" href="#publications"><i class="fas fa-book"></i> Publications</a>
    <a class="pill" href="#demo"><i class="fas fa-play-circle"></i> Demo</a>
    <a class="pill" href="#projects"><i class="fas fa-code"></i> Projects</a>
    <a class="pill" href="#honors"><i class="fas fa-award"></i> Honors</a>
    <a class="pill" href="#education"><i class="fas fa-graduation-cap"></i> Education</a>
    <a class="pill" href="#visitors"><i class="fas fa-globe"></i> Visitors</a>
  </div>
</div>

<br>

<a id="about"></a>
## About

Hello, welcome to **Shaoxiang Guo's** homepage.

I received my **Ph.D.** degree (Computer Science) from **Ocean University of China (OUC)** in 2024, under supervised by **Prof. Junyu Dong**.  
I am currently a **Postdoctoral Researcher** at **Zhejiang University** (College of Information Science and Electronic Engineering), working with **Prof. Susanto Rahardja**. Previously, I was a **Postdoctoral Research Associate** at the **National Robotarium** (Heriot-Watt University & University of Edinburgh), under supervised by **Prof. Mustafa Suphi Erden**, where I contributed to an **EPSRC-funded** project.

My research interests broadly include computer vision, machine learning, deep learning, and geometry-aware representation learning, with a focus on:

- **Monocular 3D hand pose/mesh reconstruction** 
- **Geometry-guided learning** 
- **Beam image understanding for optical alignment**
- **3D Reconstruction/Underwater Stereo Matching/Robotics**
- *(Recently exploring)* **speaker diarization** and audio representation learning

<a id="contact"></a>
## Contact

- **Email**: [gsx311381@gmail.com](mailto:gsx311381@gmail.com) ¬∑ [guoshaoxiang@stu.ouc.edu.cn](mailto:guoshaoxiang@stu.ouc.edu.cn)

- **Profiles**:
  <a class="pill" href="https://scholar.google.com/citations?user=dtqh5RQAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Google Scholar</a>
  <a class="pill" href="https://orcid.org/0000-0001-6836-284X" target="_blank" rel="noopener">ORCID</a>
  <a class="pill" href="https://www.researchgate.net/profile/Shaoxiang-Guo" target="_blank" rel="noopener">ResearchGate</a>

- **Code**:
  <a class="pill" href="https://github.com/ShaoXiang23" target="_blank" rel="noopener">GitHub</a>

<a id="experience"></a>
## Experience

- **Postdoctoral Researcher**, Zhejiang University (ZJU), Hangzhou, China, **Dec 2025 ‚Äì Present**  
  Advisor: Prof. Susanto Rahardja

- **Postdoctoral Research Associate**, National Robotarium (Heriot-Watt University & University of Edinburgh), Edinburgh, UK, **Sep 2024 ‚Äì Aug 2025**  
  Advisor: Prof. Mustafa Suphi Erden  
  Collaborators: Prof. Mike J. Chantler, Prof. M. J. Daniel Esser, Dr. Richard M. Carter, Dr. Donald Risbridger

<a id="publications"></a>
## Publications

<p><b>Notes:</b> First author*; Co-author#.</p>

<ul>

  <li>
    <b>Shaoxiang Guo</b>* , Donald Risbridger* , Richard Carter, Xianwen Kong, Daniel Esser, Mike Chantler, Mustafa Suphi Erden.<br>
    ‚ÄúA Two-Stage Learning Framework with a Beam Dataset for Automatic Laser Resonator Alignment.‚Äù<br>
    <b>Pattern Recognition</b>, <b>2026</b>. (SCI Q1, Top, Latest IF=7.6)
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> <a href="">[Dataset]</a> -->
  </li>

  <li>
    <b>Shaoxiang Guo</b>* , Qing Cai, Wankun Chen, Jingyi Sun, Junyu Dong, Hui Yu.<br>
    ‚ÄúPseudo Stereo for Camera Space Hand Pose and Shape Estimation from Monocular Image.‚Äù<br>
    Knowledge-Based Systems <b>(KBS)</b>, <b>2025</b>. (SCI Q1, Top, Latest IF=7.6)
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

  <li>
    Fanxu Min, <b>Shaoxiang Guo</b># , Hao Fan, Junyu Dong.<br>
    ‚ÄúGaitMA: Pose-guided Multi-modal Feature Fusion for Gait Recognition.‚Äù<br>
    IEEE International Conference on Multimedia and Expo <b>(ICME)</b>, <b>2024</b>. (CCF-B)
    <!-- <a href="">[PDF]</a> -->
  </li>

  <li>
    <b>Shaoxiang Guo</b>* , Qing Cai, Lin Qi and Junyu Dong.<br>
    <a href="https://dl.acm.org/doi/10.1145/3581783.3612390">
      ‚ÄúCLIP-Hand3D: Exploiting 3D Hand Pose Estimation via Context-Aware Prompting.‚Äù
    </a><br>
    ACM International Conference on Multimedia <b>(ACM MM)</b>, <b>2023</b>. (CCF-A)
    &nbsp; <a href="https://github.com/ShaoXiang23/CLIP_Hand_Demo">[Code]</a>
    <!-- <a href="">[PDF]</a> -->
  </li>

  <li>
    Jingyi Sun, <b>Shaoxiang Guo</b># , Junyu Dong.<br>
    ‚ÄúA Multi-Task Interaction Mechanism for 3D Hand Pose Estimation From RGB Image.‚Äù<br>
    IEEE International Conference on Ubiquitous Intelligence and Computing <b>(UIC)</b>, <b>2023</b>. (CCF-C)
    <!-- <a href="">[PDF]</a> -->
  </li>

  <li>
    <b>Shaoxiang Guo</b>* , Eric Rigall, Yakun Ju, Junyu Dong.<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/9680673/">
      ‚Äú3D Hand Pose Estimation From Monocular RGB With Feature Interaction Module.‚Äù
    </a><br>
    IEEE Transactions on Circuits and Systems for Video Technology <b>(IEEE T-CSVT)</b>, <b>2022</b>. (SCI Q1, Top, Latest IF=11.1)
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

  <li>
    <b>Shaoxiang Guo</b>* , Eric Rigall, Lin Qi, Xinghui Dong, Haiyan Li and Junyu Dong.<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/9680673/">
      ‚ÄúGraph-Based CNNs With Self-Supervised Module for 3D Hand Pose Estimation From Monocular RGB.‚Äù
    </a><br>
    IEEE Transactions on Circuits and Systems for Video Technology <b>(IEEE T-CSVT)</b>, <b>2021</b>. (SCI Q1, Top, Latest IF=11.1)
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

  <li>
    Amanuel Hirpa Madessa, Junyu Dong, Eric Rigall, Qingxuan Lv, Hafiza Sadia Nawaz Nawaz, Israel Mugunga and <b>Shaoxiang Guo</b>.<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/9950355">
      ‚ÄúTransmittance Surface Detection and Material Identification Using Multitask ViT-SIFT Fusion.‚Äù
    </a><br>
    IEEE Transactions on Instrumentation and Measurement <b>(IEEE T-IM)</b>, <b>2022</b>.
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

  <li>
    Yakun Ju, Muwei Jian, <b>Shaoxiang Guo</b>, Yingyu Wang, Huiyu Zhou, Junyu Dong.<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/9481150">
      ‚ÄúIncorporating Lambertian Priors into Surface Normals Measurement.‚Äù
    </a><br>
    IEEE Transactions on Instrumentation and Measurement <b>(IEEE T-IM)</b>, <b>2021</b>.
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

  <li>
    Xinyuan Song, <b>Shaoxiang Guo</b>, Zhenfu Yu and Junyu Dong.<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/9886734">
      ‚ÄúAn Encoder-Decoder Network with Residual and Attention Blocks for Full-Face 3D Gaze Estimation.‚Äù
    </a><br>
    International Conference on Image, Vision and Computing <b>(ICIVC)</b>, <b>2022</b>.
    <!-- <a href="">[PDF]</a> <a href="">[Code]</a> -->
  </li>

</ul>

<a id="demo"></a>
## Demo

<p>
  Selected system and research demos. Click a card to open the video.
</p>

<div class="demo-grid">

  <!-- 1) Laser resonator alignment -->
  <a class="demo-card" href="https://www.youtube.com/watch?v=Y2_CL1JyBng" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo1.png' | relative_url }}" alt="Demo: Automatic Laser Resonator Alignment">
    </div>
    <div class="demo-body">
      <div class="demo-tag">YouTube</div>
      <div class="demo-title">Automatic Laser Resonator Alignment</div>
      <div class="demo-desc">
        A real-world demonstration of a learning-based, coarse-to-fine alignment system for optical resonators,
        validated on hardware with beam-profile feedback.
      </div>
    </div>
  </a>

  <!-- 2) Monocular two-hand 3D reconstruction -->
  <a class="demo-card" href="https://drive.google.com/file/d/1b5HXJzWn8SYyl-6T-VeqX24cm6BgwGzr/view" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo2.png' | relative_url }}" alt="Demo: Monocular Two-Hand 3D Reconstruction">
    </div>
    <div class="demo-body">
      <div class="demo-tag">Google Drive</div>
      <div class="demo-title">Monocular Two-Hand 3D Reconstruction</div>
      <div class="demo-desc">
        Reconstructing 3D geometry of two hands from a single RGB stream, focusing on camera-space structure and robust interaction handling.
      </div>
    </div>
  </a>

  <!-- 3) Hand pose estimation -->
  <a class="demo-card" href="https://drive.google.com/file/d/1hTFWWoC1p27ofxgKCUKKnrLJcgV7j2TY/view" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo3.png' | relative_url }}" alt="Demo: Monocular 3D Hand Pose Estimation">
    </div>
    <div class="demo-body">
      <div class="demo-tag">Google Drive</div>
      <div class="demo-title">Monocular 3D Hand Pose Estimation</div>
      <div class="demo-desc">
        A monocular 3D hand pose estimation pipeline featuring geometry-aware representations and robust inference.
      </div>
    </div>
  </a>

  <!-- 4) Gesture recognition -->
  <a class="demo-card" href="https://drive.google.com/file/d/1yS9MTQ0KTx4AjR8lAG2_QrUkk21S3WvJ/view" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo4.png' | relative_url }}" alt="Demo: Vision-Based Gesture Recognition">
    </div>
    <div class="demo-body">
      <div class="demo-tag">Google Drive</div>
      <div class="demo-title">Vision-Based Gesture Recognition</div>
      <div class="demo-desc">
        A practical gesture recognition system for human‚Äìcomputer interaction, designed for stable real-time performance.
      </div>
    </div>
  </a>

  <!-- 5) Gait recognition system -->
  <a class="demo-card" href="https://drive.google.com/file/d/19aA9ruK_JbwvVduVwIFJ4at8P6SWwgWB/view" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo5.png' | relative_url }}" alt="Demo: Gait Recognition System">
    </div>
    <div class="demo-body">
      <div class="demo-tag">Google Drive</div>
      <div class="demo-title">Gait Recognition System</div>
      <div class="demo-desc">
        A gait recognition demo leveraging pose-guided multi-modal cues, targeting robust identification under appearance variations.
      </div>
    </div>
  </a>

  <!-- 6) Humanoid robot imitation -->
  <a class="demo-card" href="https://drive.google.com/file/d/1Lx5mv-4OCsTzcO0y0ytb4DF8Zr952TL5/view" target="_blank" rel="noopener">
    <div class="demo-media">
      <img class="demo-thumb" src="{{ '/images/demo6.png' | relative_url }}" alt="Demo: Humanoid Robot Motion Imitation">
    </div>
    <div class="demo-body">
      <div class="demo-tag">Google Drive</div>
      <div class="demo-title">Humanoid Robot Motion Imitation</div>
      <div class="demo-desc">
        Motion imitation on a humanoid platform, integrating perception and control to reproduce human-like actions.
      </div>
    </div>
  </a>

</div>

<a id="projects"></a>

## Projects

- Beam-profile dataset construction for optical alignment (image collection, pairing strategy, labeling, validation)
- Real-world laser resonator alignment system (coarse-to-fine regression + iterative refinement, hardware-in-the-loop experiments)
- Monocular 3D hand mesh reconstruction framework (training-time geometric supervision; camera-space reconstruction)
- *(Exploring)* speaker diarization pipelines and model reproduction for real-world audio

<a id="honors"></a>
## Honors and Awards

- Excellent Graduate, Ocean University of China, 2024
- National Scholarship (PhD), Ocean University of China & Ministry of Education of the People's Republic of China, 2022
- Academic Scholarship, Ocean University of China, 2020‚Äì2023
- LEICE Chuangxin "Minzhi" Scholarship, Ocean University of China, 2023
- Excellent Graduate Student, Ocean University of China, 2023
- Excellent Graduate Student, Ocean University of China, 2021
- "Internet+" Innovation and Entrepreneurship Competition, Second Prize, Ocean University of China, 2021
- Second Class Academic Scholarship, Ocean University of China, 2018‚Äì2019
- Mobile Robotics Challenge, First Prize, ROS Summer School, Tsinghua University (Shenzhen), 2018
- LiDAR Recognition Challenge, Second Prize, ROS Summer School, Tsinghua University (Shenzhen), 2018

<a id="education"></a>
## Education

- Ph.D., Computer Application Technology, Faculty of Information Science and Engineering, Ocean University of China, **2020‚Äì2024**
- M.Eng., Software Engineering, School of Information Science and Engineering, Ocean University of China, **2017‚Äì2020**
- B.Eng., Software Engineering, School of Information Science and Engineering, Qufu Normal University, **2013‚Äì2017**

<hr>

<a id="visitors"></a>
<h2>Visitors</h2>

<div class="widget-card widget-visitormap">
  <div class="widget-title">Live visitor map</div>
  <div class="widget-subtitle">Thanks for stopping by üëã</div>

  <div class="widget-body">
    <script type="text/javascript" id="mapmyvisitors"
      src="//mapmyvisitors.com/map.js?d=sdjqhFlAiYvLQLsgorr7ShJJGlZiH6btYejO4nUhiek&cl=ffffff&w=a">
    </script>
  </div>
</div>

